% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[11pt]{article}


\usepackage{graphicx,url}
\usepackage{proof}
\usepackage{framed}
\usepackage{etaremune}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{paralist}

\usepackage[most]{tcolorbox}

\definecolor{bg}{rgb}{0.9,0.9,0.9}%-- try others later
\definecolor{lightgray}{rgb}{0.95,0.95,0.95}%-- try others later
\definecolor{block-gray}{gray}{0.9}%-- try others later
\definecolor{dark-gray}{gray}{0.86} %-- try others later
\definecolor{light-gray}{gray}{0.96} %-- try others later
\newtcolorbox{myquote}{colback=block-gray,breakable,boxrule=0pt}
\newtcolorbox{mydarkquote}{colback=dark-gray,breakable,boxrule=0pt}
\newtcolorbox{mylightquote}{colback=light-gray,breakable,boxrule=0pt}


% 1. To get version suitable for students to populate,
%    remove the contents of the \ignoreSoln{..body..}
%
% 2. To get a version suitable for generating PDF 
%    without solutions, remove the #1 below
%
% 3. To generate solutions, keep the #1 below
%
% 4. Assigned grader fills \ignoreSoln{..body..}
%    and also provides his/her feedback to student
%    and policy followed for point deduction
%    So design policy before grading begins.

\newcommand{\ignoreSoln}[1]{#1}   
%\newcommand{\ignoreModel}[1]{#1} 


\newcommand{\bigset}[2]{\big\{\;#1\;:\;#2\;\big\}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Np}{\mathbb{N^{+}}}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\DeclareMathSizes{14}{14}{14}{14}

\begin{document}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

%\renewcommand{\qedsymbol}{\filledbox}


\begin{center}
\begin{Large}
\sf Fixpoint Theory Notes -- based on Zohar Manna's papers
\end{Large}
\end{center}

\begin{Large}

  \noindent These are meant as steps you can check off
  as you read about the Fixpoint Theory of programs.
  %
  Kindly have two papers in front of you:
  {\tt manna-fp-theory-1.pdf} and {\tt manna-fp-theory-2.pdf}.
  %
  These are under {\tt papers/} on Canvas.


  \begin{enumerate}

  \item \verb|[ ]| \label{step1}
    Some notations and simplification rules:

    \begin{compactitem}
    \item I inherit the notation below from Steven Johnson's
      excellent PhD dissertation from 1985 where he used
      recursion equations to compile into hardware circuits.
      %
      \[(P \rightarrow Q, R)\]
      %
      This means, if P then Q else R, where $P$, $Q$ and $R$ can
      themselves be conditionals.

    \item Here are some rules for simplifying conditional
      expressions. Most of them are of the form of ``if-lifting:''
      %
      \begin{compactitem}
      \item ``if-lifting'' -- pulling the predicates to the
        top level -- is a handy simplification rule.
        In general, you can do this if you are careful
        about thinking about termination (you don't want the
        program after if-lifting to be less defined, i.e.
        ``loop more often.'')
        
      \item This is one form of ``if-lifting''. Here ``$+$'' is
        for illustration; it can be any operator.
        \[(P \rightarrow Q, R) + X =
                    (P \rightarrow Q+X, R+X)
        \]

      \item This helps process nested conditionals:        \[(P \rightarrow (P_1\rightarrow Q_1,R_1), R) \]
        can simplify to
        \[ (P\wedge P_1 \rightarrow Q_1,
        \; P\wedge \neg P_1 \rightarrow R_1,
        \; \neg P \rightarrow R)
        \]
        
      \end{compactitem}

    \item There are many more such rules 
    \end{compactitem}
    
\item \verb|[ ]| \label{step2}
  The first thing I'll get ``out of your way'' is the recursive
  function {\tt F} and the solutions for {\tt F} in the form
  of three distinct functions {\tt f1}, {\tt f2}, and {\tt f3}.
  %
  All these are fixpoints of the {\tt Tau}
  functional underlying
  {\tt F}.
  %
  Of these, {\tt f3} is {\bf the} least fixpoint.
  %
  These functions defined in manna-fp-theory-1.pdf are reproduced
  below.
  %
  Here on, I'm using {\tt bottom} for the bottom (undefined)
  value and {\tt BOTTOM} for the undefined (bottom) function.
  %
  Recall that {\tt BOTTOM(x) = bottom} for any {\tt x}.

\begin{verbatim}
F(x,y) = (x=y) -> y+1, F(x, F(x-1, y+1))
f1(x,y) = (x=y) -> (y+1), (x+1)
f2(x,y) = (x>=y) -> (x+1), (y-1)
f3(x,y) = (x>=y) /\ even(x-y) -> (x+1), bottom
  \end{verbatim}
  
\item \verb|[ ]| 
You can unfold {\tt F} as a series of approximations.
manna-fp-theory-1.pdf shows this in Section 1.2 for the simpler
"Factorial" function.
%
I'll show the unfolding for the aforesaid {\tt F} function.

\begin{verbatim}
F_0 = Tau^0[BOTTOM] = BOTTOM
F_1 = Tau^1[BOTTOM] = Tau[Tau^0[BOTTOM]] = (x=y) -> y+1, bottom
\end{verbatim}

\item \verb|[ ]| Now,
\begin{verbatim}  
F_2 = Tau^2[BOTTOM] = Tau[Tau^1[BOTTOM]] =
\end{verbatim}
is obtained by substituting {\tt Lambda x,y : (x=y) -> y+1, bottom}
in place of "F".
We get
\begin{footnotesize}
\begin{verbatim}  
  (x=y) -> y+1,

  (x = [(x-1 = y+1) -> y+1+1, bottom]) ->          ; Detail (*) below

       [(x-1 = y+1) -> y+1+1, bottom] + 1 , bottom ; Detail (**) below

\end{verbatim}
\end{footnotesize}
\item \verb|[ ]|
  Now, focus on the line {\tt (*)} above:
  
  {\tt   (x = [(x-1 = y+1) -> y+1+1, bottom]) -> }

  includes only one meaningful case in it, namely {\tt x=y+1+1}
  or that {\tt x=y+2}.

  In fact, we  can simplify the above line to the nested
  conditional

  {\tt   [(x-1 = y+1) -> [(x = y+1+1) -> ... , ElseWhoCares] ..] }

\item \verb|[ ]| This is because all other cases involve
  {\tt bottom}, and so {\tt ElseWhoCares} are those bottom-cases.

\item \verb|[ ]| Now, coming to (**),
  notice that the ``y'' field for the
  outer call is
  {\tt [(x-1 = y+1) -> y+1+1, bottom]}
  and it is ``that y'' that has to be incremented by 1.

\item \verb|[ ]| The expression
  {\tt [(x-1 = y+1) -> (y+1+1), bottom] + 1 }
  
  can be simplified to

  {\tt [(x = y+2) -> (y+1+1)+1, (bottom+1)]}

 
\item \verb|[ ]| Thus, together with (*) and (**),
  the whole can be simplified to
  
    {\tt [(x = y+2) -> (y+3), bottom]}
  
  \item \verb|[ ]| So
\begin{verbatim}
    F_2 = Tau^2[BOTTOM] = Tau[Tau^1[BOTTOM]] 
\end{verbatim}
simplifies to
\begin{verbatim}  
  (x=y) -> y+1,
  (x = y+2) -> y+3, bottom
\end{verbatim}

\item \verb|[ ]|
  Now,
\begin{verbatim}    
F_3 = Tau^3[BOTTOM] = Tau[Tau^2[BOTTOM]]
\end{verbatim}
and
by now, you have to "see" how this unraveling is going, and write
the answer directly as below. The trick to "seeing" this answer is
to focus on the inner-most recursion of {\tt F} which is decreasing
{\tt x} and increasing {\tt y} each time. This means that the final
conditional that decides things is of the form x = y+4.
Then once you
land at that conditional, it is easy to see that the answer returned
is y+5, otherwise it is "bottom everywhere". Thus we get

\item \verb|[ ]|
\begin{verbatim}  
  (x=y) -> y+1,
  (x = y+2) -> y+2, bottom 
  (x = y+4) -> y+5, bottom
\end{verbatim}


\item \verb|[ ]|
  Now for context-free grammars being interpreted as
  a system of recursive equations.
  Consider the CFG

\begin{verbatim}
S -> aSbS | bSaS | epsilon
\end{verbatim}

If \verb|L_S| denotes ``the language of S,'' one can also
view the aforesaid CFG production scheme being a language
equation of the form shown below, following how we are
supposed to read CFG rules right-hand sides (here \verb|U|
means union):

\begin{verbatim}
L_S  = {a} L_S {b} L_S   U   {b} L_S {a} L_S   U   {epsilon}
\end{verbatim}


\item \verb|[ ]| The above language equation has a unique
  solution, namely the least fixpoint, which is the
  set of all strings over $\{a,b\}$.

  In particular, $\{a,b\}^*$ cannot be a solution
  because the LHS when substituted with
  $\{a,b\}^*$ can contain, say, ``bb'', while
  the RHS can never contain a {\tt b} without an {\tt a}.

\item \verb|[ ]| Introducing any redundancy such as

  \begin{verbatim}
S -> aSbS | bSaS | epsilon | S
\end{verbatim}

  or

\begin{verbatim}
S -> aSbS | bSaS | epsilon | SS
\end{verbatim}  


allows us to obtain $\{a,b\}^*$ as another solution.
%
This ``extraneous'' solution cannot be computed by
following the CFG derivation rules---much like functions
{\tt f1} and {\tt f2} mentioned earlier are ``out of thin air''
solutions---not modeling how programs laboriously construct
the answer by following the strict recipe of recursive calls.

\item \verb|[ ]| Why an extraneous solution? 
  This is because we can substitute   $\{a,b\}^*$ for the {\tt S}
  on both sides of the equation. Then the Union operator
  blends the LHS and RHS into equality, by applying
  the union ({\tt U}) operator.

\item \verb|[ ]|
  Is mutual recursion any different, in terms of how
  we approach things?
  The answer is ``no''.
  %
  We are solving for a {\em pair} (in general a tuple)
  of functions in those cases.
  %
  Consider this mutual recursion:

\begin{verbatim}
f1(x) = even(x) -> x+1, f2(x)
f2(x) = odd(x) -> f1(x+2), x+1
  \end{verbatim}

It is clear that both {\tt f1} and {\tt f2} compute the
same function: successor of evens if given an even input, otherwise
(for odd inputs) being undefined.
%
Here, we can Lambda-abstract and write it as a recursion:

\begin{footnotesize}
\begin{verbatim}
(f1,f2) = [ Lambda G: (lambda x: even(x) -> x+1, snd(G)(x),
                       lambda x: odd(x) -> fst(G)(g), x+1 ) ] (f1,f2)
\end{verbatim}
\end{footnotesize}

In other words, we are solving for a {\em pair} of functions
{\tt (f1,f2)} simultaneously.
%
This is evident from the fact that the Tau functional we write
has a {\tt Lambda G} outside, where {\tt G} has type ``a pair
of functions.''
%
This is why, inside the function body, we use
{\tt snd(G)} (second of {\tt G}) and
{\tt fst(G)} (first of {\tt G}).


\item  \verb|[ ]|
  Now we can do a fixpoint itertion as follows, to discover
  the ``pair solution'' (call it {\tt f12} and
  let the approximants be \verb|f12_0|, \verb|f12_1|, etc.):

  \begin{footnotesize}
\begin{verbatim}

Tau = 
[ Lambda G:  (lambda x: even(x) -> x+1, snd(G)(x),
                        lambda x: odd(x) -> fst(G)(g), x+1 )  ] 

f12_0 = [ BOTTOM, BOTTOM ]  ; the pair of bottom functions

f12_1 = Tau(f12_0)

      = [ lambda x: even(x) -> x+1, BOTTOM(x),
          lambda x: odd(x) -> BOTTOM(g), x+1 )  ]

      = [ lambda x: even(x) -> x+1, bottom,
          lambda x: odd(x) -> bottom, x+1 )  ]

f12_2 = Tau(f12_1)

      = [ lambda x: even(x) -> x+1, snd(f12_1)(x),
          lambda x: odd(x) -> fst(f12_1)(g), x+1 )  ]
...
  \end{verbatim}
  \end{footnotesize}

\item Now consider CFG productions that are mutually recursive.
  The same argument -- modeling the languages as a pair -- works.
%
We iterate from {\tt (BOTTOM, BOTTOM)} which, in case of languages,
is $(\emptyset, \emptyset)$.

\begin{verbatim}
S -> ( W S | epsilon  ; I'll abbreviate epsilon as e, below.

W -> ( W W | )
\end{verbatim}

\item \verb|[ ]| The above can be solved as a pair of languages:

\begin{verbatim}
(L_S, L_W) = [  {(} L_W L_S  U  {e} ,
                {() L_W L_W  U  {)} ]
  \end{verbatim}

\item \verb|[ ]| We iterate from {\tt ({}, {})} as "(BOTTOM, BOTTOM)"
and this stabilizes to the pair language solution. Then from this
solution, we can pick \verb|L_S| as the first component
of  the solution fixpoint,
and
\verb|L_W| as the second component of the solution fixpoint.
  
\end{enumerate}

\end{Large}
\end{document}

 \item \verb|[ ]|
First, we will try to prove this -- call it {\bf Case-1}:\\
   {\bf $W_S$ is valid implies S has a solution.}

 \item \verb|[ ]| Next, we will try to prove this -- call it {\bf Case-2}:\\
   {\bf S has a solution implies $W_S$ is valid.}

 \item \verb|[ ]| For {\bf Case-1}, assume $W_S$ is valid. That
   means we can pick any interpretation we like (to achieve our goal,
   which is $S$ has a solution). So pick the following interpretation.

\begin{list}{$\bullet$}{\addtolength{\itemsep}{-1.6\itemsep}}
\item[] $\displaystyle a = \varepsilon$
\item[] $\displaystyle f_0(x) = x0$ (string `$x$' and string `$0$' concatenated)
\item[] $\displaystyle f_1(x) = x1$ (similar to the above)
\item[] $\displaystyle p(x,y)$ = There exists a non-empty
                                sequence $i_1 i_2 \ldots i_m$ such that
\item[] $\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;  x = \alpha_{i_1}\alpha_{i_2}\ldots\alpha_{i_m}$ and
                                $y = \beta_{i_1}\beta_{i_2}\ldots\beta_{i_m}$ 
\end{list}
%--
   

\item \verb|[ ]| Under this interpretation, we can see that each
  conjunct of $A_1$ is true. So $A_1$ as a whole is true. This is
  because $p$ says that ``it must see one block being
  fed to it.''

\item \verb|[ ]| Under this interpretation, we can see that inside
  the $\forall$, if we keep $x$ and $y$ general, then
  we have to decide if the following is true:
  \begin{itemize}
    \item $[p(x,y) \Rightarrow \wedge_{i=1}^{n} \; p(f_{\alpha_i}(x), f_{\beta_i}(y))] $
  \end{itemize}
  But first let's stare at this, for some $i$:
  \begin{itemize}
  \item $[p(x,y) \Rightarrow  \; p(f_{\alpha_i}(x), f_{\beta_i}(y))] $
  \end{itemize}

\item \verb|[ ]|
  Now,   $[p(x,y) \Rightarrow  \; p(f_{\alpha_i}(x), f_{\beta_i}(y))] $ is true for some $i$. This is because ``p says'' the following: if $x,y$
  are as per a consistent $\alpha$ and $\beta$ concatenation,
  we can extend it by one more $\alpha$ or $\beta$ concatenation.
  That is, we are making a longer listing similar to \\
  $\alpha_{4} \;  \alpha_{3}  \; \alpha_{1} \; \alpha_{4} \; \alpha_{2}$\\
  and\\
  $\beta_{4} \; \beta_{3}  \; \beta_{1} \; \beta_{4} \; \beta_{2}$.


\item \verb|[ ]|
  Thus, $A_2$ as a whole is true, where $A_2$ is as follows:\\
$\textstyle \forall x\; \forall y\;
  [p(x,y) \Rightarrow \wedge_{i=1}^{n} \; p(f_{\alpha_i}(x), f_{\beta_i}(y))] \;\;\;\;\;\;\;\; $ 
  

\item \verb|[ ]| So we know that  $A_1$ and $A_2$ are true. Also
  we know that $(A_1\wedge A_2\Rightarrow C)$ is true because
  we are working under {\bf Case-1} which assumes $W_S$ is valid.


\item \verb|[ ]| Thus $C$ must be true!

\item \verb|[ ]| This means that the PCP system $S$ has a solution! That is
  what $C$ says!  {\bf So, Case-1 is proven!}

\item \verb|[ ]|
  Next, we will try to prove  {\bf Case-2}:\\
   {\bf S has a solution implies $W_S$ is valid.}

\item \verb|[ ]|   
  Since $S$ has a solution, there is a sequence
  ${i1}, {i2}, \ldots, {in}$ such that \\
  $\alpha_{i1} \alpha_{i2} \ldots \alpha_{in} =
   \beta_{i1} \beta_{i2} \ldots \beta_{in}$.


 \item \verb|[ ]| We must show $W_S$ is valid -- true under
   all interpretations!

 \item \verb|[ ]|   
   So we can't assume any particular meaning
   for $p$, $f_0$, and $f_1$. Remember that things like 
   $f_{\alpha_i}$, $f_{1011}$, etc are abbreviations. We really
   only have $f_0$ and $f_1$ as our function symbols.

 \item \verb|[ ]|   But $W_S$ is of the form
   $(A_1 \wedge A_2 \Rightarrow C)$ and we are asked to show
   it is valid!

 \item \verb|[ ]| It is silly to consider the case
   of $A_1$ or $A_2$ being false -- because then $W_S$ would
   be true. Thus we can assume that $A_1$ and $A_2$ are true,
   and show that $C$ is true -- under all interpretations!

\item    Then we would have shown that
   $(A_1 \wedge A_2 \Rightarrow C)$ is valid.

\item \verb|[ ]| But we know that $S$ has a solution. So we exploit that.

\item \verb|[ ]|  
  Consider
  $A_1$. {\bf We are  assuming $A_1$ is true, and so we exploit that fact.}
  We can take $A_1$ and see that it asserts something
     rather simple. It asserts $n$ facts of this form:
   $ 
\textstyle \wedge_{i=1}^{n} \; p(f_{\alpha_i}(a), f_{\beta_i}(a)) \;\;\;\;\;\;\;\;  $      

\item \verb|[ ]| \label{step-x}
  Take {\bf one of these facts asserted by $A_1$.}
  And in fact,
  choose the {\em particular fact} following the solution $S$: \\
   $ 
\textstyle \; p(f_{\alpha_{i_1}}(a), f_{\beta_{i_1}}(a)) \;\;\;\;\;\;\;\;  $      
  

 \item \verb|[ ]| Fine. Have a coffee or beer before you continue!

 \item \verb|[ ]| Now, {\bf we are assuming that $A_2$ is true.}
   
 \item \verb|[ ]| We can interpret $A_2$ as a ``bag of inference
   rules.''
   
 \item \verb|[ ]| \label{step-y}
   $A_2 =$
$\textstyle 
   [p(x,y) \Rightarrow \wedge_{i=1}^{n} \; p(f_{\alpha_i}(x), f_{\beta_i}(y))] \;\;\;\;\;\;\;\; $

 \item \verb|[ ]|      Notice that in the above step,
   we can infer one big conjunct. We choose to infer one
   of those conjuncts only!
   
   
\item \verb|[ ]| Thus, we can ``pattern match'' the fact in
  Step~\ref{step-x} with the rule in   Step~\ref{step-y}
  and infer, using modus ponens, the following:

  \[ p(f_{\alpha_{i_2}} ( f_{\alpha_{i_1}} ( a)),
       f_{\beta_{i_2}} ( f_{\beta_{i_1}} ( a)) ) \]
  
  
  
     \item \verb|[ ]| Wow, this game is fun and we can keep inferring
       bigger and bigger things! We infer next, the following:


       \[ p(f_{\alpha_{i_3}} ( f_{\alpha_{i_2}} ( f_{\alpha_{i_1}} ( a))),
          p(f_{\beta_{i_3}} ( f_{\beta_{i_2}} ( f_{\beta_{i_1}} ( a)))) \]
       
        \item \verb|[ ]| Till finally we infer this:
\[ p(f_{\alpha_{i_1}\alpha_{i_2} \ldots\alpha_{i_m}}(a),
     f_{\beta_{i_1}\beta_{i_2} \ldots\beta_{i_m}}(a)). \]          

   \item \verb|[ ]|
     But we now know that
     \[ \alpha_{i_1}\alpha_{i_2}\ldots\alpha_{i_m} = \beta_{i_1}\beta_{i_2}\ldots\beta_{i_m} = Soln, \] because ``$S$ has a solution'' -- call it $Soln$.

   \item Thus  we inferred
     \( p(f_{Soln}(a), f_{Soln}(a)) \).

   \item \verb|[ ]|
     This means that we inferred $C$ is true !!


   \item \verb|[ ]|
     Thus, without assuming any interpretation at all,
     assuming $A_1$ and $A_2$, we showed that $C$ is true.

   \item \verb|[ ]|   Thus we showed that $W_S$ is valid. This
     finishes {\bf Case-2}.
  
\end{enumerate}

\end{Large}

\end{document}
%==

